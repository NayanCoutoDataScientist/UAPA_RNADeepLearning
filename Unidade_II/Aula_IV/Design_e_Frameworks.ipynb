{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Exemplo prático usando o Keras",
   "id": "db3fd756b0fe45cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Passo 1 – Carregar os dados.**\n",
    "\n",
    "Uma vez instalado os frameworks TensorFlow e Keras, você precisará carregar a base de dados utilizada para a criação do modelo usando uma arquitetura clássica de rede neural.\n",
    " \n",
    "Para isso, importe as bibliotecas necessárias para o desenvolvimento da aplicação conforme ilustrado na Figura 1."
   ],
   "id": "9142f21d74258700"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:23:00.046987Z",
     "start_time": "2024-06-07T03:22:45.361718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from numpy import loadtxt\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ],
   "id": "80edfaeae30acf50",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Após a importação das bibliotecas, carregue a base de dados pública Pima Indians Diabetes, como mostrado na Figura 2.\n",
    "\n",
    "Essa base possui inicialmente 9 colunas, sendo as 8 primeiras as características da população indígena e a última a saída desejada.\n",
    "\n",
    "Todas as entradas e a saída dessa base de dados são numéricas, facilitando o processamento dos dados por modelos de Deep Learning.\n",
    "\n",
    "Por fim, separe o conjunto de dados entre dados de entrada (x) e saída (y)."
   ],
   "id": "482d31789869405d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## carregue a base de dados",
   "id": "90fe14d95547997e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:27:14.125200Z",
     "start_time": "2024-06-07T03:27:14.115758Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = loadtxt('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv', delimiter=',')",
   "id": "eda4744886c5959",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Separe os dados em x e y",
   "id": "e3a48a526056a2d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:27:23.138448Z",
     "start_time": "2024-06-07T03:27:23.132204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = dataset[:,0:8]\n",
    "y = dataset[:,8]"
   ],
   "id": "eed72caa50b63589",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "No framework Keras, a arquitetura da rede neural é vista como uma sequência de camadas.\n",
    "\n",
    "Neste tutorial, vamos criar um modelo sequencial e adicionar uma camada de cada vez.\n",
    "\n",
    "Primeiramente, você precisa garantir que a camada de entrada da rede neural tenha a quantidade correta de características modeladas na aplicação, ou seja, a camada de entrada precisa conter oito neurônios referente as oito características levantadas.\n",
    "\n",
    "Isso pode ser especificado no Keras utilizando o parâmetro input_dim e ajustando-o para 8, como demonstrado na Figura 3."
   ],
   "id": "b747b6319e053f23"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Defina o modelo com keras",
   "id": "3571760cba325763"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:27:35.303674Z",
     "start_time": "2024-06-07T03:27:35.296669Z"
    }
   },
   "cell_type": "code",
   "source": "model = Sequential()",
   "id": "5eb77d524cf7fbff",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inicializa primeira camada oculta, com 12 neurônios, 8 entradas, e a função de ativação relu.",
   "id": "1448fb4ce204654b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:29:06.883001Z",
     "start_time": "2024-06-07T03:29:06.640017Z"
    }
   },
   "cell_type": "code",
   "source": "model.add(Dense(12, input_dim=8, activation='relu'))",
   "id": "34a535690b76d768",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nayan Couto\\.conda\\envs\\POO\\Lib\\site-packages\\keras\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Adiciona a segunda camada, com 8 neurônios e a função de ativação relu.",
   "id": "4882ad4cf694eca9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:29:33.496690Z",
     "start_time": "2024-06-07T03:29:33.474805Z"
    }
   },
   "cell_type": "code",
   "source": "model.add(Dense(8, activation='relu'))",
   "id": "880444245707ec1e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Adiciona a ultima camada, com 1 neurônio e a função de ativação sigmoid.",
   "id": "6bfae4fdcd630386"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:30:02.803237Z",
     "start_time": "2024-06-07T03:30:02.779829Z"
    }
   },
   "cell_type": "code",
   "source": "model.add(Dense(1, activation='sigmoid'))",
   "id": "c8326e95e36066fc",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A arquitetura utilizada neste tutorial contém, além da camada de entrada, três camadas, as quais as duas primeiras utilizaram a função de ativação ReLU e a última, função sigmoide. \n",
    "\n",
    "No Keras, utilizando a classe Dense, pode-se especificar o número de neurônios e a função de ativação presente na camada atual, ilustrado na Figura 3.\n",
    "\n",
    "**Passo 3 – Configurar o modelo.**\n",
    "\n",
    "A configuração do modelo diz respeito aos demais hiperparâmetros usados durante o processo de treinamento, tais como a função de perda, o otimizador e a métrica que será utilizada para avaliar o modelo, demonstrado na Figura 4."
   ],
   "id": "4e4c68a93f1bb901"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compile o modelo no keras",
   "id": "1a3e357e84a6225"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:31:22.479447Z",
     "start_time": "2024-06-07T03:31:22.457475Z"
    }
   },
   "cell_type": "code",
   "source": "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])",
   "id": "3441be8a31536ba0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Passo 4 | Treinar o modelo.**\n",
    "\n",
    "Com a arquitetura do modelo definida e compilada, precisamos treiná-lo, ou seja, executar o modelo utilizando o conjunto de dados.\n",
    "\n",
    "Para treinar o modelo, basta chamar a função fit() para o modelo.\n",
    "\n",
    "Os principais hiperparâmetros da função fit(), além dos dados de entrada e saída, são a quantidade máxima de épocas e o tamanho do lote, apresentado na Figura 5."
   ],
   "id": "22c210ee90f9243d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:33:34.748746Z",
     "start_time": "2024-06-07T03:33:05.029883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Treine o modelo no keras\n",
    "model.fit(x, y, epochs=150, batch_size=10)"
   ],
   "id": "8a1c3f3f96d24dc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.3354 - loss: 18.1211\n",
      "Epoch 2/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.3705 - loss: 5.3918\n",
      "Epoch 3/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4059 - loss: 1.4835\n",
      "Epoch 4/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6224 - loss: 0.6813\n",
      "Epoch 5/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6771 - loss: 0.6509\n",
      "Epoch 6/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6851 - loss: 0.6065\n",
      "Epoch 7/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6636 - loss: 0.6273\n",
      "Epoch 8/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6690 - loss: 0.6093\n",
      "Epoch 9/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6554 - loss: 0.6244\n",
      "Epoch 10/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7041 - loss: 0.5839\n",
      "Epoch 11/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6785 - loss: 0.6034\n",
      "Epoch 12/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6874 - loss: 0.5964\n",
      "Epoch 13/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6886 - loss: 0.5771\n",
      "Epoch 14/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6571 - loss: 0.6002\n",
      "Epoch 15/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6696 - loss: 0.5909\n",
      "Epoch 16/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6651 - loss: 0.5969\n",
      "Epoch 17/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6496 - loss: 0.6018\n",
      "Epoch 18/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6983 - loss: 0.5742\n",
      "Epoch 19/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6671 - loss: 0.5857\n",
      "Epoch 20/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6993 - loss: 0.5765\n",
      "Epoch 21/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6799 - loss: 0.5751\n",
      "Epoch 22/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7162 - loss: 0.5602\n",
      "Epoch 23/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6870 - loss: 0.5851\n",
      "Epoch 24/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7143 - loss: 0.5550\n",
      "Epoch 25/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6955 - loss: 0.5755\n",
      "Epoch 26/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6817 - loss: 0.5818\n",
      "Epoch 27/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6656 - loss: 0.5966\n",
      "Epoch 28/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7152 - loss: 0.5659\n",
      "Epoch 29/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7127 - loss: 0.5787\n",
      "Epoch 30/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7124 - loss: 0.5628\n",
      "Epoch 31/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7053 - loss: 0.5695\n",
      "Epoch 32/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6767 - loss: 0.6013\n",
      "Epoch 33/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7066 - loss: 0.5627\n",
      "Epoch 34/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6744 - loss: 0.5828\n",
      "Epoch 35/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6986 - loss: 0.5722\n",
      "Epoch 36/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6863 - loss: 0.5862\n",
      "Epoch 37/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6602 - loss: 0.5916\n",
      "Epoch 38/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6854 - loss: 0.5662\n",
      "Epoch 39/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7066 - loss: 0.5567\n",
      "Epoch 40/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7119 - loss: 0.5460\n",
      "Epoch 41/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6811 - loss: 0.5749\n",
      "Epoch 42/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6963 - loss: 0.5736\n",
      "Epoch 43/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6744 - loss: 0.5752\n",
      "Epoch 44/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6966 - loss: 0.5462\n",
      "Epoch 45/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6870 - loss: 0.5666\n",
      "Epoch 46/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6911 - loss: 0.5669\n",
      "Epoch 47/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6974 - loss: 0.5678\n",
      "Epoch 48/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6684 - loss: 0.5896\n",
      "Epoch 49/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6801 - loss: 0.5829\n",
      "Epoch 50/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6957 - loss: 0.5721\n",
      "Epoch 51/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7119 - loss: 0.5595\n",
      "Epoch 52/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6748 - loss: 0.5865\n",
      "Epoch 53/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7083 - loss: 0.5613\n",
      "Epoch 54/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7011 - loss: 0.5797\n",
      "Epoch 55/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6929 - loss: 0.5673\n",
      "Epoch 56/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7355 - loss: 0.5546\n",
      "Epoch 57/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6967 - loss: 0.5617\n",
      "Epoch 58/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7096 - loss: 0.5628\n",
      "Epoch 59/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7121 - loss: 0.5587\n",
      "Epoch 60/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6950 - loss: 0.5591\n",
      "Epoch 61/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6846 - loss: 0.5783\n",
      "Epoch 62/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7108 - loss: 0.5735\n",
      "Epoch 63/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7101 - loss: 0.5409\n",
      "Epoch 64/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6918 - loss: 0.5781\n",
      "Epoch 65/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7156 - loss: 0.5614\n",
      "Epoch 66/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7126 - loss: 0.5472\n",
      "Epoch 67/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6634 - loss: 0.5878\n",
      "Epoch 68/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7139 - loss: 0.5452\n",
      "Epoch 69/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7136 - loss: 0.5570\n",
      "Epoch 70/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6856 - loss: 0.5709\n",
      "Epoch 71/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7110 - loss: 0.5541\n",
      "Epoch 72/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7007 - loss: 0.5471\n",
      "Epoch 73/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7036 - loss: 0.5623\n",
      "Epoch 74/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6995 - loss: 0.5626\n",
      "Epoch 75/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7019 - loss: 0.5628\n",
      "Epoch 76/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7092 - loss: 0.5652\n",
      "Epoch 77/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6744 - loss: 0.5680\n",
      "Epoch 78/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6889 - loss: 0.5560\n",
      "Epoch 79/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7400 - loss: 0.5327\n",
      "Epoch 80/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7036 - loss: 0.5471\n",
      "Epoch 81/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7060 - loss: 0.5632\n",
      "Epoch 82/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6994 - loss: 0.5616\n",
      "Epoch 83/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7060 - loss: 0.5488\n",
      "Epoch 84/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7237 - loss: 0.5406\n",
      "Epoch 85/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7049 - loss: 0.5569\n",
      "Epoch 86/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7098 - loss: 0.5429\n",
      "Epoch 87/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6949 - loss: 0.5547\n",
      "Epoch 88/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6975 - loss: 0.5505\n",
      "Epoch 89/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7371 - loss: 0.5406\n",
      "Epoch 90/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6895 - loss: 0.5396\n",
      "Epoch 91/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7134 - loss: 0.5650\n",
      "Epoch 92/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7451 - loss: 0.5292\n",
      "Epoch 93/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6912 - loss: 0.5528\n",
      "Epoch 94/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7369 - loss: 0.5231\n",
      "Epoch 95/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7432 - loss: 0.5390\n",
      "Epoch 96/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7070 - loss: 0.5590\n",
      "Epoch 97/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6739 - loss: 0.5744\n",
      "Epoch 98/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6960 - loss: 0.5646\n",
      "Epoch 99/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7246 - loss: 0.5369\n",
      "Epoch 100/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6992 - loss: 0.5562\n",
      "Epoch 101/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7211 - loss: 0.5340\n",
      "Epoch 102/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7089 - loss: 0.5443\n",
      "Epoch 103/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7080 - loss: 0.5233\n",
      "Epoch 104/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6831 - loss: 0.5627\n",
      "Epoch 105/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7110 - loss: 0.5390\n",
      "Epoch 106/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7054 - loss: 0.5452\n",
      "Epoch 107/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7140 - loss: 0.5550\n",
      "Epoch 108/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7352 - loss: 0.5177\n",
      "Epoch 109/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7135 - loss: 0.5370\n",
      "Epoch 110/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7443 - loss: 0.5158\n",
      "Epoch 111/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6905 - loss: 0.5503\n",
      "Epoch 112/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7108 - loss: 0.5597\n",
      "Epoch 113/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6797 - loss: 0.5637\n",
      "Epoch 114/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7420 - loss: 0.5265\n",
      "Epoch 115/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7359 - loss: 0.5335\n",
      "Epoch 116/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7178 - loss: 0.5367\n",
      "Epoch 117/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7261 - loss: 0.5320\n",
      "Epoch 118/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7221 - loss: 0.5460\n",
      "Epoch 119/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7350 - loss: 0.5242\n",
      "Epoch 120/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7176 - loss: 0.5364\n",
      "Epoch 121/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7118 - loss: 0.5437\n",
      "Epoch 122/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7016 - loss: 0.5413\n",
      "Epoch 123/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7576 - loss: 0.4950\n",
      "Epoch 124/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7341 - loss: 0.5105\n",
      "Epoch 125/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7362 - loss: 0.5147\n",
      "Epoch 126/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7261 - loss: 0.5101\n",
      "Epoch 127/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6984 - loss: 0.5642\n",
      "Epoch 128/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7008 - loss: 0.5548\n",
      "Epoch 129/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7020 - loss: 0.5460\n",
      "Epoch 130/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7450 - loss: 0.5237\n",
      "Epoch 131/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7359 - loss: 0.5356\n",
      "Epoch 132/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7307 - loss: 0.5274\n",
      "Epoch 133/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7265 - loss: 0.5333\n",
      "Epoch 134/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7250 - loss: 0.5367\n",
      "Epoch 135/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7396 - loss: 0.5049\n",
      "Epoch 136/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7418 - loss: 0.5192\n",
      "Epoch 137/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7346 - loss: 0.5246\n",
      "Epoch 138/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7218 - loss: 0.5171\n",
      "Epoch 139/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7029 - loss: 0.5413\n",
      "Epoch 140/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7302 - loss: 0.5181\n",
      "Epoch 141/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7036 - loss: 0.5348\n",
      "Epoch 142/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7585 - loss: 0.5287\n",
      "Epoch 143/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7308 - loss: 0.5232\n",
      "Epoch 144/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7479 - loss: 0.5072\n",
      "Epoch 145/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7302 - loss: 0.5175\n",
      "Epoch 146/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7606 - loss: 0.4843\n",
      "Epoch 147/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7268 - loss: 0.5236\n",
      "Epoch 148/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7624 - loss: 0.5006\n",
      "Epoch 149/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7350 - loss: 0.5109\n",
      "Epoch 150/150\n",
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7389 - loss: 0.5060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.history.History at 0x25e556dddd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Passo 5 – Avaliar o desempenho do modelo.**\n",
    "\n",
    "Agora que você treinou o modelo, precisa avaliá-lo.\n",
    "\n",
    "Essa avaliação vai demonstrar o quão bom é o seu modelo na fase de predição utilizando o conjunto de dados de treinamento.\n",
    "\n",
    "Este tutorial foi construído para ser simples, mas você pode separar os dados entre dados de treinamento e de teste para avaliar o desempenho do modelo com novos dados usando os dados de teste.\n",
    "\n",
    "\n",
    "Para avaliar como o modelo se comportou para os dados de treinamento, basta passar os mesmos dados de entrada e saída para a função evaluate().\n",
    "\n",
    "Essa função retorna uma lista com a perda e a acurácia do modelo para o conjunto de dados, como ilustrado na Figura 6."
   ],
   "id": "2e004bd46b098e14"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Avalie o modelo",
   "id": "5bafac841738079b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:35:42.903257Z",
     "start_time": "2024-06-07T03:35:42.777249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss, accuracy = model.evaluate(x, y)\n",
    "print('Acurácia: %.2f' % (accuracy*100))\n",
    "print('Perda: %.2f' % (loss))"
   ],
   "id": "92e034055e288a5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7279 - loss: 0.5110 \n",
      "Acurácia: 75.78\n",
      "Perda: 0.49\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "346ed86d61778ac5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Videoaula: Design e frameworks",
   "id": "29b1f85435f60814"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Os frameworks estão cada vez mais difundidos e utilizados no desenvolvimento de aplicações, economizando tempo e dinheiro.\n",
    "- Por serem projetados, testados, otimizados e atualizados por programadores experientes, os frameworks tendem a ser seguros e eficientes.\n",
    "- Principais frameworks para desenvolvimento de Redes Neurais: TensorFlow e Keras.\n",
    "- O Tensor Flow doi originalmente desenvolvido em 2015 por pesquisadores e engenheiros que trabalhavam na equipe do Google Brain.\n",
    "- Existem APIs do TensorFlow em várias linguagens, como Python, C++ e C#.\n",
    "- O TensorFlow é multiplataforma, podendo ser executado no Windows, MacOS ou Linux.\n",
    "- Keras é uma API de Deep Learning de código aberto desenvolvida em Python.\n",
    "- Foco em permitir experimentação rápida, com o intuito de ser fácil de usar, modular e extensível.\n",
    "- Em 2017, a equipe do TensorFlow do Google decidiu apoiar o Keras na biblioteca principal do TensorFLow 2.0"
   ],
   "id": "9763a6f5db40ffe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "44bcadc4c3cb88d7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
