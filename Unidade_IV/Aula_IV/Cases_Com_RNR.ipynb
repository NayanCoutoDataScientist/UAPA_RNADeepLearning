{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Videoaula: Cases com redes neurais recorrentes",
   "id": "4bcab288f3674efc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Redes Neurais Artificiais Recorrentes no Processamento de Linguagem Natural**\n",
    "\n",
    "> A persistência destes modelos é uma de suas maiores vantagens.\n",
    "> \n",
    "> Neste modelo ocorrem loops transitando a informação entre camadas, propagando pela rede. Nos modelos tradicionais não se armazena informação\n",
    "> \n",
    "> As RNNs são estruturadas de modo que possuam um loop no qual a informação é passada de uma camada para a outra, permitindo assim, que se propague através da rede.\n",
    "> \n",
    "> Aplicações: Reconhecimento de padrões em textos, traduções, legendas de imagens, reconhecimento de voz.\n",
    "> \n",
    "> Este recurso permite automatizar processos pelo uso da simulação da linguagem humana, nos setores industrial, educacional e comercial.\n",
    "\n",
    "**Modelo Transformers**\n",
    "> Um modelo de rede neural que aprende pelo contexto, significado e com as relações em dados sequenciais.\n",
    "> \n",
    "> Usa técnicas matemáticas de atenção ou autodetecção, para detectar a dependência entre os dados, mesmo que excessivamente distantes.\n",
    "> \n",
    "> Considerado um modelo novo e de grande força e efetividade já criados, surge em um artigo de 2017 oferecido pelo Google.\n",
    "> \n",
    "> Transformers são capazes de traduzir um texto, uma fala em tempo real, o que, se aplicado na tradução de idiomas, permite conversas entre pessoas de outras nações.\n",
    "> \n",
    "> O DNA é uma aplicação importante, com os transformers facilitando a compreensão das cadeias de genes, permitindo desenvolvimento de novos medicamentos mais facilmente.\n",
    "\n",
    "**Sequence to Sequence**\n",
    "> Usa uma sequência como entrada, passa a sequência para ser representada em outro domínio.\n",
    "> \n",
    "> Pega uma sequência de probabilidades de saida e maximiza a probabilidade de certa sequência anterior como sua entrada.\n",
    "> \n",
    "> Aplicações\n",
    ">> Software capaz de realizar perguntas e respostas automaticamente.\n",
    ">>\n",
    ">> Treinamento de chatbots.\n",
    ">>\n",
    ">> Criação de bases de conhecimento.\n",
    ">>\n",
    ">> Interpretação de textos.\n",
    ">>\n",
    ">> Tradução neural de máquinas.\n",
    "\n",
    "**Encoders e Decoders**\n",
    "> Forma de aumentar a capacidade das redes neurais de aprender representações.\n",
    "> \n",
    "> Com base em uma rede de codificadores as entradas são mapeadas em estado bruto para representações de recursos.\n",
    "> \n",
    "> Em seguida, a rede de descodificadores se apropria desta representação de recursos como sendo sua entrada.\n",
    "> \n",
    "> Esta entrada é processada, uma decisão é tomada e produz uma saída.\n",
    "> \n",
    "> Sua vantagem é poder usar o codificador e descodificador de forma independente. Mas usar em conjunto melhora seu desempenho."
   ],
   "id": "d90e7c1027def1a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Importamos as bibliotecas necessárias\n",
    "\n",
    "from tf_keras.models import Sequential\n",
    "\n",
    "from tf_keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import tensorflow as tf"
   ],
   "id": "c6a3d99716057188",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset, info = tfds.load('imdb_reviews/subwords8k',\n",
    "\n",
    "                          with_info=True,\n",
    "\n",
    "                          as_supervised=True)\n",
    "\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ],
   "id": "1c801c7a5ce1ad25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "encoder = info.features['text'].encoder\n",
    "\n",
    "test_string = 'Esta é uma frase de teste'4\n",
    "\n",
    "encoded_string = encoder.encode(test_string)\n",
    "\n",
    "print('String codificada is {}'.format(encoded_string))\n",
    "\n",
    "original_string = encoder.decode(encoded_string)\n",
    "\n",
    "print('String original: \"{}\"'.format(original_string))"
   ],
   "id": "6b15b6a0c3cbdb38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "BUFFER_SIZE = 10\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE)\n",
    "\n",
    "test_dataset = test_dataset.padded_batch(BATCH_SIZE)"
   ],
   "id": "8ddeeabeb5273e1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Embedding(encoder.vocab_size, 16),\n",
    "\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
    "\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "\n",
    "    tf.keras.layers.Dense(1)\n",
    "\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "train_history1 = model.fit(train_dataset, epochs=20,\n",
    "\n",
    "                           validation_data=test_dataset,\n",
    "\n",
    "                           validation_steps=100)"
   ],
   "id": "78e85cfb521bc234",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_training(history, lw = 3):\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    plt.subplot(2,1,1)\n",
    "    \n",
    "    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n",
    "    \n",
    "    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    \n",
    "    plt.title('Accuracy')\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    \n",
    "    plt.ylabel('Accuracy')\n",
    "    \n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    \n",
    "    plt.subplot(2,1,2)\n",
    "    \n",
    "    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n",
    "    \n",
    "    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    \n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    \n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.show()"
   ],
   "id": "b5334c2dd7d0fa92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_acc))"
   ],
   "id": "85bf1a1d077245e4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
