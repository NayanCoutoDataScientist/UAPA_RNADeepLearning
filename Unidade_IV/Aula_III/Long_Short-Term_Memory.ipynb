{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Videoaula: Long Short-Term Memory",
   "id": "a720c5037aac985d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sobre o LSTM",
   "id": "837e89778f5e63b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> LSTM é a sigla para Long Short-Term Memory, ou seja, memória de longo e curto prazo.\n",
    "> \n",
    "> Essa arquitetura consegue capturar tanto o logo quanto o curto prazo, resolvendo o problema que ocorre quando se usa, nos modelos tradicionais de RNN, apenas o curtíssimo prazo.\n",
    "> \n",
    "> Neste modelo, a prioridade é o fluxo de informações, que passam a circular em maior intensidade.\n",
    "> \n",
    "> O fluxo funciona desta forma: uma certa entrada vai passar por todo um circuito e assim gerar um estado específico. No passo seguinte temos o estado anterior, diferente de uma mesma entrada retroalimentada.\n",
    "\n",
    "**Camadas Profundas**\n",
    "> Normalmente, as RNN's não apresentam muitas camadas em profundidade. Assim, são raras as arquiteturas com mais de três LSTMs sobrepostas.\n",
    "> \n",
    "> Mas em redes de maior densidade, pode ser aplicados conjuntos de até 10 camadas profundas.\n",
    "> \n",
    "> O que determina a quantidade de camadas profundas é a complexidade do problema, do tamanho da rede neural.\n",
    "> \n",
    "> Não é muito comum encontrar redes LSTM nesta configuração.\n",
    "> \n",
    "> Podem existir modelos específicos com mais de 15 camadas. Em alguns casos, quando o LSTM é utilizado, temos que a saída é a entrada de outra camada neural.\n",
    "\n",
    "**Variações do LSTM**\n",
    "> Com o tempo, diversas mudanças no LSTM foram criadas para simplificar o design interno das células.\n",
    "> \n",
    "> Foram criadas as conexões de olho mágico revelando o conhecimento sobre o estado da célula a cada instante.\n",
    "> \n",
    "> Foi criada a técnica de entrada acoplada e porta de esquecimento, saindo do modelo de duas portas separadas, permitindo ao modelo tomar decisões simultâneamente.\n",
    "> \n",
    "> A redução do número de portões pela combinação do estado da célula e do estado oculto, somando a porta de atualização e as portas de entrada.\n",
    "\n",
    "**Desvantagens do LSTM**\n",
    "> Os LSTMs não são capazes de resolver o problema de gradientes por completo, problema centrado em fatos como a complexidade das células.\n",
    "> \n",
    "> A quantidade de recursos e tempo para serem treinados, o que demanda alta largura de banda na memória do sistema.\n",
    "> \n",
    "> Devido a mineração de dados, existe a procura por modelos capazes de lembrar informações do passado de forma mais permanente.\n",
    "> \n",
    "> Desenvolvedores buscam baixos pesos, mas as redes LSTM puxam os pesos aleatórios como redes feed-forward.\n",
    "> \n",
    "> LSTMs são muito suscetíveis ao overfitting, sendo complexo e oneroso a aplicação do modelo dropout que ajusta este detalhe."
   ],
   "id": "fa968953bb115951"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
